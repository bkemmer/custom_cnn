{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from glob import glob\n",
    "from skimage import data, io, feature, color, exposure\n",
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.patches import Rectangle\n",
    "from sklearn.decomposition import PCA\n",
    "import seaborn as sns\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Paper: Face Recognition Based on HOG and Fast PCA Algorithm\n",
    "\n",
    "    1- Viola Jones\n",
    "    2- Resize = 64x128\n",
    "    3- HOG:\n",
    "        3780 HOG features\n",
    "    4- PCA\n",
    "    5- Normalização: median normalization method (Eq 10)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# declare functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "lfw2 = os.path.join('..', 'Data', 'lfw2')\n",
    "def image_path(person, id_, lfw_folder = lfw2):\n",
    "    return glob(os.path.join(lfw_folder, person, '*' + id_ + '.jpg'))[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Parameters: \n",
    "    - img_matrix: (ndarray)\n",
    "    - title: (string)\n",
    "Output:\n",
    "    - image plot\n",
    "'''\n",
    "def plt_img(img_matrix, title='Image', normalize=False):\n",
    "    if normalize:\n",
    "        plt.imshow(img_matrix, vmin=np.min(img_matrix), vmax=np.max(img_matrix), cmap='gray')\n",
    "    else:\n",
    "        io.imshow(img_matrix)\n",
    "    plt.title(title)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plt_two_imgs(img_a, img_b, cmap='gray', normalize=False):\n",
    "    f = plt.figure(figsize=(12, 8))\n",
    "    f.add_subplot(1,2, 1)\n",
    "    if normalize:\n",
    "        plt.imshow(img_a, vmin=np.min(img_matrix), vmax=np.max(img_matrix), cmap=cmap)\n",
    "    else:\n",
    "        plt.imshow(img_a, cmap=cmap)\n",
    "    f.add_subplot(1,2, 2)\n",
    "    if normalize:\n",
    "        plt.imshow(img_b, vmin=np.min(img_matrix), vmax=np.max(img_matrix), cmap=cmap)\n",
    "    else:\n",
    "        plt.imshow(img_b, cmap=cmap)\n",
    "    \n",
    "    plt.show(block=True)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Parameters: \n",
    "- Path: The image should be in the working directory or a full path of image\n",
    "should be given;\n",
    "- color: Second argument is a flag which specifies the way image should be read.\n",
    "    cv2.IMREAD_COLOR : Loads a color image. Any transparency of image\n",
    "    will be neglected;\n",
    "    cv2.IMREAD_GRAYSCALE : Loads image in grayscale mode;\n",
    "    cv2.IMREAD_UNCHANGED : Loads image as such including alpha channel;\n",
    "Note Instead of these three flags, you can simply pass integers 1, 0 or -1\n",
    "respectively.\n",
    "Output:\n",
    "- img_array: (ndarray)\n",
    "'''\n",
    "def open_img(path, color=0):\n",
    "    return cv2.imread(path, color)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Parameters:\n",
    "- path_img: A string representing the file name. The filename must include image format like .jpg, .png, etc.\n",
    "\n",
    "- img: It is the image that is to be saved (ndarray).\n",
    "\n",
    "Return Value: It returns true if image is saved successfully.\n",
    "'''\n",
    "\n",
    "def save_img(path_img, img):\n",
    "    cv2.imwrite(path_img, img) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getDF(path):\n",
    "    with open(path) as f:\n",
    "        file_list = f.readlines()\n",
    "    n = int(file_list[0].strip())\n",
    "    df_inicial = pd.read_csv(path, sep='\\t', skiprows=1, nrows=n, names=['pair_name_1', 'pair_id_1', 'pair_id_2'])\n",
    "    df_inicial['pair_name_2'] = None\n",
    "    df_secondary = pd.read_csv(path, sep='\\t', skiprows=n+1, names=['pair_name_1', 'pair_id_1', 'pair_name_2', 'pair_id_2'])\n",
    "    df = pd.concat([df_inicial, df_secondary])\n",
    "    df = df.reset_index(drop=True)\n",
    "    print(df.shape)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plt_img_batch(df, show=False, limit=np.inf):\n",
    "    for index, row in df.iterrows():\n",
    "        plt_img(open_img(row['path_pair_id_1'], color=0), title=os.path.split(row['path_pair_id_1'])[-1].split('.')[0])\n",
    "        plt_img(open_img(row['path_pair_id_2'], color=0), title=os.path.split(row['path_pair_id_2'])[-1].split('.')[0])\n",
    "        if limit == index + 1:\n",
    "            break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_folder = os.path.abspath('..\\\\data\\\\')\n",
    "data_folder = os.path.join('..', 'Data')\n",
    "train_path = Path(data_folder, 'pairsDevTrain.txt')\n",
    "test_path = Path(data_folder, 'pairsDevTest.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2200, 4)\n",
      "(1000, 4)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:8: FutureWarning: Sorting because non-concatenation axis is not aligned. A future version\n",
      "of pandas will change to not sort by default.\n",
      "\n",
      "To accept the future behavior, pass 'sort=False'.\n",
      "\n",
      "To retain the current behavior and silence the warning, pass 'sort=True'.\n",
      "\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "df_train = getDF(train_path)\n",
    "df_test = getDF(test_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train['path_pair_id_1'] = df_train.apply(lambda x: image_path(person=x['pair_name_1'], id_= str(x['pair_id_1'])), axis=1)\n",
    "df_train['path_pair_id_2'] = df_train.apply(lambda x: image_path(person=x['pair_name_1'], id_= str(x['pair_id_2'])) if x['pair_name_2']==None \n",
    "                                            else image_path(person=x['pair_name_2'], id_= str(x['pair_id_2'])), axis=1)\n",
    "\n",
    "df_test['path_pair_id_1'] = df_test.apply(lambda x: image_path(person=x['pair_name_1'], id_= str(x['pair_id_1'])), axis=1)\n",
    "df_test['path_pair_id_2'] = df_test.apply(lambda x: image_path(person=x['pair_name_1'], id_= str(x['pair_id_2'])) if x['pair_name_2']==None \n",
    "                                          else image_path(person=x['pair_name_2'], id_= str(x['pair_id_2'])), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pair_id_1</th>\n",
       "      <th>pair_id_2</th>\n",
       "      <th>pair_name_1</th>\n",
       "      <th>pair_name_2</th>\n",
       "      <th>path_pair_id_1</th>\n",
       "      <th>path_pair_id_2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>Aaron_Peirsol</td>\n",
       "      <td>None</td>\n",
       "      <td>..\\Data\\lfw2\\Aaron_Peirsol\\Aaron_Peirsol_0001.jpg</td>\n",
       "      <td>..\\Data\\lfw2\\Aaron_Peirsol\\Aaron_Peirsol_0002.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>Aaron_Peirsol</td>\n",
       "      <td>None</td>\n",
       "      <td>..\\Data\\lfw2\\Aaron_Peirsol\\Aaron_Peirsol_0003.jpg</td>\n",
       "      <td>..\\Data\\lfw2\\Aaron_Peirsol\\Aaron_Peirsol_0004.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>Aaron_Sorkin</td>\n",
       "      <td>None</td>\n",
       "      <td>..\\Data\\lfw2\\Aaron_Sorkin\\Aaron_Sorkin_0001.jpg</td>\n",
       "      <td>..\\Data\\lfw2\\Aaron_Sorkin\\Aaron_Sorkin_0002.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>Abdel_Nasser_Assidi</td>\n",
       "      <td>None</td>\n",
       "      <td>..\\Data\\lfw2\\Abdel_Nasser_Assidi\\Abdel_Nasser_...</td>\n",
       "      <td>..\\Data\\lfw2\\Abdel_Nasser_Assidi\\Abdel_Nasser_...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Abdullah</td>\n",
       "      <td>None</td>\n",
       "      <td>..\\Data\\lfw2\\Abdullah\\Abdullah_0001.jpg</td>\n",
       "      <td>..\\Data\\lfw2\\Abdullah\\Abdullah_0003.jpg</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   pair_id_1  pair_id_2          pair_name_1 pair_name_2  \\\n",
       "0          1          2        Aaron_Peirsol        None   \n",
       "1          3          4        Aaron_Peirsol        None   \n",
       "2          1          2         Aaron_Sorkin        None   \n",
       "3          1          2  Abdel_Nasser_Assidi        None   \n",
       "4          1          3             Abdullah        None   \n",
       "\n",
       "                                      path_pair_id_1  \\\n",
       "0  ..\\Data\\lfw2\\Aaron_Peirsol\\Aaron_Peirsol_0001.jpg   \n",
       "1  ..\\Data\\lfw2\\Aaron_Peirsol\\Aaron_Peirsol_0003.jpg   \n",
       "2    ..\\Data\\lfw2\\Aaron_Sorkin\\Aaron_Sorkin_0001.jpg   \n",
       "3  ..\\Data\\lfw2\\Abdel_Nasser_Assidi\\Abdel_Nasser_...   \n",
       "4            ..\\Data\\lfw2\\Abdullah\\Abdullah_0001.jpg   \n",
       "\n",
       "                                      path_pair_id_2  \n",
       "0  ..\\Data\\lfw2\\Aaron_Peirsol\\Aaron_Peirsol_0002.jpg  \n",
       "1  ..\\Data\\lfw2\\Aaron_Peirsol\\Aaron_Peirsol_0004.jpg  \n",
       "2    ..\\Data\\lfw2\\Aaron_Sorkin\\Aaron_Sorkin_0002.jpg  \n",
       "3  ..\\Data\\lfw2\\Abdel_Nasser_Assidi\\Abdel_Nasser_...  \n",
       "4            ..\\Data\\lfw2\\Abdullah\\Abdullah_0003.jpg  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pair_id_1</th>\n",
       "      <th>pair_id_2</th>\n",
       "      <th>pair_name_1</th>\n",
       "      <th>pair_name_2</th>\n",
       "      <th>path_pair_id_1</th>\n",
       "      <th>path_pair_id_2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>14</td>\n",
       "      <td>Abdullah_Gul</td>\n",
       "      <td>None</td>\n",
       "      <td>..\\Data\\lfw2\\Abdullah_Gul\\Abdullah_Gul_0013.jpg</td>\n",
       "      <td>..\\Data\\lfw2\\Abdullah_Gul\\Abdullah_Gul_0014.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "      <td>16</td>\n",
       "      <td>Abdullah_Gul</td>\n",
       "      <td>None</td>\n",
       "      <td>..\\Data\\lfw2\\Abdullah_Gul\\Abdullah_Gul_0013.jpg</td>\n",
       "      <td>..\\Data\\lfw2\\Abdullah_Gul\\Abdullah_Gul_0016.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>Abdullatif_Sener</td>\n",
       "      <td>None</td>\n",
       "      <td>..\\Data\\lfw2\\Abdullatif_Sener\\Abdullatif_Sener...</td>\n",
       "      <td>..\\Data\\lfw2\\Abdullatif_Sener\\Abdullatif_Sener...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Adel_Al-Jubeir</td>\n",
       "      <td>None</td>\n",
       "      <td>..\\Data\\lfw2\\Adel_Al-Jubeir\\Adel_Al-Jubeir_000...</td>\n",
       "      <td>..\\Data\\lfw2\\Adel_Al-Jubeir\\Adel_Al-Jubeir_000...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>Al_Pacino</td>\n",
       "      <td>None</td>\n",
       "      <td>..\\Data\\lfw2\\Al_Pacino\\Al_Pacino_0001.jpg</td>\n",
       "      <td>..\\Data\\lfw2\\Al_Pacino\\Al_Pacino_0002.jpg</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   pair_id_1  pair_id_2       pair_name_1 pair_name_2  \\\n",
       "0         13         14      Abdullah_Gul        None   \n",
       "1         13         16      Abdullah_Gul        None   \n",
       "2          1          2  Abdullatif_Sener        None   \n",
       "3          1          3    Adel_Al-Jubeir        None   \n",
       "4          1          2         Al_Pacino        None   \n",
       "\n",
       "                                      path_pair_id_1  \\\n",
       "0    ..\\Data\\lfw2\\Abdullah_Gul\\Abdullah_Gul_0013.jpg   \n",
       "1    ..\\Data\\lfw2\\Abdullah_Gul\\Abdullah_Gul_0013.jpg   \n",
       "2  ..\\Data\\lfw2\\Abdullatif_Sener\\Abdullatif_Sener...   \n",
       "3  ..\\Data\\lfw2\\Adel_Al-Jubeir\\Adel_Al-Jubeir_000...   \n",
       "4          ..\\Data\\lfw2\\Al_Pacino\\Al_Pacino_0001.jpg   \n",
       "\n",
       "                                      path_pair_id_2  \n",
       "0    ..\\Data\\lfw2\\Abdullah_Gul\\Abdullah_Gul_0014.jpg  \n",
       "1    ..\\Data\\lfw2\\Abdullah_Gul\\Abdullah_Gul_0016.jpg  \n",
       "2  ..\\Data\\lfw2\\Abdullatif_Sener\\Abdullatif_Sener...  \n",
       "3  ..\\Data\\lfw2\\Adel_Al-Jubeir\\Adel_Al-Jubeir_000...  \n",
       "4          ..\\Data\\lfw2\\Al_Pacino\\Al_Pacino_0002.jpg  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Viola Jones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_rectangle(detected_faces, image, title='Image', cmap_type='gray', kwargs={'lw': 20.}):\n",
    "    # Create figure and axes\n",
    "    fig,ax = plt.subplots(1)\n",
    "    # Display the image\n",
    "    ax.imshow(image, cmap=cmap_type)\n",
    "    plt.title(title)\n",
    "    for (column, row, width, height) in detected_faces:\n",
    "        rect = Rectangle(\n",
    "                (column, row),\n",
    "                width = width,\n",
    "                height = height,\n",
    "                fill=False,\n",
    "                edgecolor='r',\n",
    "                \n",
    "                )\n",
    "        # Add the patch to the Axes\n",
    "        ax.add_patch(rect)\n",
    "#     plt.axis('off')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def crop_image(original_image, column, row, width, height):\n",
    "    # the goal is crop the biggest area\n",
    "    return original_image[row:row+height, column:column + width]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the classifier and create a cascade object for face detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "cascade_path = os.path.join('..', 'haarcascades', 'haarcascade_frontalface_alt.xml')\n",
    "face_cascade = cv2.CascadeClassifier(cascade_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem: what image to use?\n",
    "### Response: Use the biggest area"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def crop_biggest_area(original_image, detected_faces):\n",
    "    \n",
    "    # the goal is crop the biggest area\n",
    "    if len(detected_faces) == 0: # viola jones didnt recognize any face\n",
    "        return original_image, (None, None, original_image.shape[0], original_image.shape[1])\n",
    "    else:\n",
    "        # detected_faces returns: column, row, width, height\n",
    "        # So, assuming all width == height\n",
    "        # get np.argmax of height\n",
    "        id_max_max_width = np.argmax(detected_faces[:, -1])\n",
    "        column, row, width, height = detected_faces[id_max_max_width]\n",
    "        return crop_image(original_image, column, row, width, height), (column, row, width, height)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem: images with differents shapes\n",
    "### Response: Use the resize methods. So, cropped all images, then used resize methods to get a standard shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Update df_train and df_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train['path_pair_id_1_cropped'] = df_train['path_pair_id_1'].apply(lambda x: x.replace('lfw2', 'lfw2_cropped'))\n",
    "_ = df_train['path_pair_id_1_cropped'].apply(lambda x: None if os.path.isdir(os.path.split(x)[0]) else os.mkdir(os.path.split(x)[0]))\n",
    "\n",
    "df_train['path_pair_id_2_cropped'] = df_train['path_pair_id_2'].apply(lambda x: x.replace('lfw2', 'lfw2_cropped'))\n",
    "_ = df_train['path_pair_id_2_cropped'].apply(lambda x: None if os.path.isdir(os.path.split(x)[0]) else os.mkdir(os.path.split(x)[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test['path_pair_id_1_cropped'] = df_test['path_pair_id_1'].apply(lambda x: x.replace('lfw2', 'lfw2_cropped'))\n",
    "_ = df_test['path_pair_id_1_cropped'].apply(lambda x: None if os.path.isdir(os.path.split(x)[0]) else os.mkdir(os.path.split(x)[0]))\n",
    "\n",
    "df_test['path_pair_id_2_cropped'] = df_test['path_pair_id_2'].apply(lambda x: x.replace('lfw2', 'lfw2_cropped'))\n",
    "_ = df_test['path_pair_id_2_cropped'].apply(lambda x: None if os.path.isdir(os.path.split(x)[0]) else os.mkdir(os.path.split(x)[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pair_id_1</th>\n",
       "      <th>pair_id_2</th>\n",
       "      <th>pair_name_1</th>\n",
       "      <th>pair_name_2</th>\n",
       "      <th>path_pair_id_1</th>\n",
       "      <th>path_pair_id_2</th>\n",
       "      <th>path_pair_id_1_cropped</th>\n",
       "      <th>path_pair_id_2_cropped</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>Aaron_Peirsol</td>\n",
       "      <td>None</td>\n",
       "      <td>..\\Data\\lfw2\\Aaron_Peirsol\\Aaron_Peirsol_0001.jpg</td>\n",
       "      <td>..\\Data\\lfw2\\Aaron_Peirsol\\Aaron_Peirsol_0002.jpg</td>\n",
       "      <td>..\\Data\\lfw2_cropped\\Aaron_Peirsol\\Aaron_Peirs...</td>\n",
       "      <td>..\\Data\\lfw2_cropped\\Aaron_Peirsol\\Aaron_Peirs...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>Aaron_Peirsol</td>\n",
       "      <td>None</td>\n",
       "      <td>..\\Data\\lfw2\\Aaron_Peirsol\\Aaron_Peirsol_0003.jpg</td>\n",
       "      <td>..\\Data\\lfw2\\Aaron_Peirsol\\Aaron_Peirsol_0004.jpg</td>\n",
       "      <td>..\\Data\\lfw2_cropped\\Aaron_Peirsol\\Aaron_Peirs...</td>\n",
       "      <td>..\\Data\\lfw2_cropped\\Aaron_Peirsol\\Aaron_Peirs...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>Aaron_Sorkin</td>\n",
       "      <td>None</td>\n",
       "      <td>..\\Data\\lfw2\\Aaron_Sorkin\\Aaron_Sorkin_0001.jpg</td>\n",
       "      <td>..\\Data\\lfw2\\Aaron_Sorkin\\Aaron_Sorkin_0002.jpg</td>\n",
       "      <td>..\\Data\\lfw2_cropped\\Aaron_Sorkin\\Aaron_Sorkin...</td>\n",
       "      <td>..\\Data\\lfw2_cropped\\Aaron_Sorkin\\Aaron_Sorkin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>Abdel_Nasser_Assidi</td>\n",
       "      <td>None</td>\n",
       "      <td>..\\Data\\lfw2\\Abdel_Nasser_Assidi\\Abdel_Nasser_...</td>\n",
       "      <td>..\\Data\\lfw2\\Abdel_Nasser_Assidi\\Abdel_Nasser_...</td>\n",
       "      <td>..\\Data\\lfw2_cropped\\Abdel_Nasser_Assidi\\Abdel...</td>\n",
       "      <td>..\\Data\\lfw2_cropped\\Abdel_Nasser_Assidi\\Abdel...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Abdullah</td>\n",
       "      <td>None</td>\n",
       "      <td>..\\Data\\lfw2\\Abdullah\\Abdullah_0001.jpg</td>\n",
       "      <td>..\\Data\\lfw2\\Abdullah\\Abdullah_0003.jpg</td>\n",
       "      <td>..\\Data\\lfw2_cropped\\Abdullah\\Abdullah_0001.jpg</td>\n",
       "      <td>..\\Data\\lfw2_cropped\\Abdullah\\Abdullah_0003.jpg</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   pair_id_1  pair_id_2          pair_name_1 pair_name_2  \\\n",
       "0          1          2        Aaron_Peirsol        None   \n",
       "1          3          4        Aaron_Peirsol        None   \n",
       "2          1          2         Aaron_Sorkin        None   \n",
       "3          1          2  Abdel_Nasser_Assidi        None   \n",
       "4          1          3             Abdullah        None   \n",
       "\n",
       "                                      path_pair_id_1  \\\n",
       "0  ..\\Data\\lfw2\\Aaron_Peirsol\\Aaron_Peirsol_0001.jpg   \n",
       "1  ..\\Data\\lfw2\\Aaron_Peirsol\\Aaron_Peirsol_0003.jpg   \n",
       "2    ..\\Data\\lfw2\\Aaron_Sorkin\\Aaron_Sorkin_0001.jpg   \n",
       "3  ..\\Data\\lfw2\\Abdel_Nasser_Assidi\\Abdel_Nasser_...   \n",
       "4            ..\\Data\\lfw2\\Abdullah\\Abdullah_0001.jpg   \n",
       "\n",
       "                                      path_pair_id_2  \\\n",
       "0  ..\\Data\\lfw2\\Aaron_Peirsol\\Aaron_Peirsol_0002.jpg   \n",
       "1  ..\\Data\\lfw2\\Aaron_Peirsol\\Aaron_Peirsol_0004.jpg   \n",
       "2    ..\\Data\\lfw2\\Aaron_Sorkin\\Aaron_Sorkin_0002.jpg   \n",
       "3  ..\\Data\\lfw2\\Abdel_Nasser_Assidi\\Abdel_Nasser_...   \n",
       "4            ..\\Data\\lfw2\\Abdullah\\Abdullah_0003.jpg   \n",
       "\n",
       "                              path_pair_id_1_cropped  \\\n",
       "0  ..\\Data\\lfw2_cropped\\Aaron_Peirsol\\Aaron_Peirs...   \n",
       "1  ..\\Data\\lfw2_cropped\\Aaron_Peirsol\\Aaron_Peirs...   \n",
       "2  ..\\Data\\lfw2_cropped\\Aaron_Sorkin\\Aaron_Sorkin...   \n",
       "3  ..\\Data\\lfw2_cropped\\Abdel_Nasser_Assidi\\Abdel...   \n",
       "4    ..\\Data\\lfw2_cropped\\Abdullah\\Abdullah_0001.jpg   \n",
       "\n",
       "                              path_pair_id_2_cropped  \n",
       "0  ..\\Data\\lfw2_cropped\\Aaron_Peirsol\\Aaron_Peirs...  \n",
       "1  ..\\Data\\lfw2_cropped\\Aaron_Peirsol\\Aaron_Peirs...  \n",
       "2  ..\\Data\\lfw2_cropped\\Aaron_Sorkin\\Aaron_Sorkin...  \n",
       "3  ..\\Data\\lfw2_cropped\\Abdel_Nasser_Assidi\\Abdel...  \n",
       "4    ..\\Data\\lfw2_cropped\\Abdullah\\Abdullah_0003.jpg  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pair_id_1</th>\n",
       "      <th>pair_id_2</th>\n",
       "      <th>pair_name_1</th>\n",
       "      <th>pair_name_2</th>\n",
       "      <th>path_pair_id_1</th>\n",
       "      <th>path_pair_id_2</th>\n",
       "      <th>path_pair_id_1_cropped</th>\n",
       "      <th>path_pair_id_2_cropped</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>14</td>\n",
       "      <td>Abdullah_Gul</td>\n",
       "      <td>None</td>\n",
       "      <td>..\\Data\\lfw2\\Abdullah_Gul\\Abdullah_Gul_0013.jpg</td>\n",
       "      <td>..\\Data\\lfw2\\Abdullah_Gul\\Abdullah_Gul_0014.jpg</td>\n",
       "      <td>..\\Data\\lfw2_cropped\\Abdullah_Gul\\Abdullah_Gul...</td>\n",
       "      <td>..\\Data\\lfw2_cropped\\Abdullah_Gul\\Abdullah_Gul...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "      <td>16</td>\n",
       "      <td>Abdullah_Gul</td>\n",
       "      <td>None</td>\n",
       "      <td>..\\Data\\lfw2\\Abdullah_Gul\\Abdullah_Gul_0013.jpg</td>\n",
       "      <td>..\\Data\\lfw2\\Abdullah_Gul\\Abdullah_Gul_0016.jpg</td>\n",
       "      <td>..\\Data\\lfw2_cropped\\Abdullah_Gul\\Abdullah_Gul...</td>\n",
       "      <td>..\\Data\\lfw2_cropped\\Abdullah_Gul\\Abdullah_Gul...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>Abdullatif_Sener</td>\n",
       "      <td>None</td>\n",
       "      <td>..\\Data\\lfw2\\Abdullatif_Sener\\Abdullatif_Sener...</td>\n",
       "      <td>..\\Data\\lfw2\\Abdullatif_Sener\\Abdullatif_Sener...</td>\n",
       "      <td>..\\Data\\lfw2_cropped\\Abdullatif_Sener\\Abdullat...</td>\n",
       "      <td>..\\Data\\lfw2_cropped\\Abdullatif_Sener\\Abdullat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Adel_Al-Jubeir</td>\n",
       "      <td>None</td>\n",
       "      <td>..\\Data\\lfw2\\Adel_Al-Jubeir\\Adel_Al-Jubeir_000...</td>\n",
       "      <td>..\\Data\\lfw2\\Adel_Al-Jubeir\\Adel_Al-Jubeir_000...</td>\n",
       "      <td>..\\Data\\lfw2_cropped\\Adel_Al-Jubeir\\Adel_Al-Ju...</td>\n",
       "      <td>..\\Data\\lfw2_cropped\\Adel_Al-Jubeir\\Adel_Al-Ju...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>Al_Pacino</td>\n",
       "      <td>None</td>\n",
       "      <td>..\\Data\\lfw2\\Al_Pacino\\Al_Pacino_0001.jpg</td>\n",
       "      <td>..\\Data\\lfw2\\Al_Pacino\\Al_Pacino_0002.jpg</td>\n",
       "      <td>..\\Data\\lfw2_cropped\\Al_Pacino\\Al_Pacino_0001.jpg</td>\n",
       "      <td>..\\Data\\lfw2_cropped\\Al_Pacino\\Al_Pacino_0002.jpg</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   pair_id_1  pair_id_2       pair_name_1 pair_name_2  \\\n",
       "0         13         14      Abdullah_Gul        None   \n",
       "1         13         16      Abdullah_Gul        None   \n",
       "2          1          2  Abdullatif_Sener        None   \n",
       "3          1          3    Adel_Al-Jubeir        None   \n",
       "4          1          2         Al_Pacino        None   \n",
       "\n",
       "                                      path_pair_id_1  \\\n",
       "0    ..\\Data\\lfw2\\Abdullah_Gul\\Abdullah_Gul_0013.jpg   \n",
       "1    ..\\Data\\lfw2\\Abdullah_Gul\\Abdullah_Gul_0013.jpg   \n",
       "2  ..\\Data\\lfw2\\Abdullatif_Sener\\Abdullatif_Sener...   \n",
       "3  ..\\Data\\lfw2\\Adel_Al-Jubeir\\Adel_Al-Jubeir_000...   \n",
       "4          ..\\Data\\lfw2\\Al_Pacino\\Al_Pacino_0001.jpg   \n",
       "\n",
       "                                      path_pair_id_2  \\\n",
       "0    ..\\Data\\lfw2\\Abdullah_Gul\\Abdullah_Gul_0014.jpg   \n",
       "1    ..\\Data\\lfw2\\Abdullah_Gul\\Abdullah_Gul_0016.jpg   \n",
       "2  ..\\Data\\lfw2\\Abdullatif_Sener\\Abdullatif_Sener...   \n",
       "3  ..\\Data\\lfw2\\Adel_Al-Jubeir\\Adel_Al-Jubeir_000...   \n",
       "4          ..\\Data\\lfw2\\Al_Pacino\\Al_Pacino_0002.jpg   \n",
       "\n",
       "                              path_pair_id_1_cropped  \\\n",
       "0  ..\\Data\\lfw2_cropped\\Abdullah_Gul\\Abdullah_Gul...   \n",
       "1  ..\\Data\\lfw2_cropped\\Abdullah_Gul\\Abdullah_Gul...   \n",
       "2  ..\\Data\\lfw2_cropped\\Abdullatif_Sener\\Abdullat...   \n",
       "3  ..\\Data\\lfw2_cropped\\Adel_Al-Jubeir\\Adel_Al-Ju...   \n",
       "4  ..\\Data\\lfw2_cropped\\Al_Pacino\\Al_Pacino_0001.jpg   \n",
       "\n",
       "                              path_pair_id_2_cropped  \n",
       "0  ..\\Data\\lfw2_cropped\\Abdullah_Gul\\Abdullah_Gul...  \n",
       "1  ..\\Data\\lfw2_cropped\\Abdullah_Gul\\Abdullah_Gul...  \n",
       "2  ..\\Data\\lfw2_cropped\\Abdullatif_Sener\\Abdullat...  \n",
       "3  ..\\Data\\lfw2_cropped\\Adel_Al-Jubeir\\Adel_Al-Ju...  \n",
       "4  ..\\Data\\lfw2_cropped\\Al_Pacino\\Al_Pacino_0002.jpg  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Paper: Face Recognition Based on HOG and Fast PCA Algorithm\n",
    "\n",
    "    1- Viola Jones\n",
    "    2- Resize = 64x128\n",
    "    3- HOG:\n",
    "        3780 HOG features\n",
    "    4- PCA\n",
    "    5- Normalização: median normalization method (Eq 10)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Steps 1 and 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessing(path_image, path_to_save, dim=(100, 100)):\n",
    "    original_image = open_img(path_image, color=0)\n",
    "    grayscale_image = original_image.copy()\n",
    "    detected_faces = face_cascade.detectMultiScale(grayscale_image)# step 1\n",
    "    cropped_image, (column, row, width, height) = crop_biggest_area(original_image, detected_faces)\n",
    "    resized = cv2.resize(cropped_image, dim, interpolation = cv2.INTER_AREA) #step 2\n",
    "    save_img(path_img=path_to_save, img=resized)\n",
    "    return (column, row, width, height)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### get dimensions VJ and apply pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train['VJ_pair_id_1'] = df_train.apply(lambda x: preprocessing(path_image=x['path_pair_id_1'], path_to_save=x['path_pair_id_1_cropped'], dim=(64,128)), axis=1)\n",
    "df_train['VJ_pair_id_2'] = df_train.apply(lambda x: preprocessing(path_image=x['path_pair_id_2'], path_to_save=x['path_pair_id_2_cropped'], dim=(64,128)), axis=1)\n",
    "\n",
    "df_test['VJ_pair_id_1'] = df_test.apply(lambda x: preprocessing(path_image=x['path_pair_id_1'], path_to_save=x['path_pair_id_1_cropped'], dim=(64,128)), axis=1)\n",
    "df_test['VJ_pair_id_2'] = df_test.apply(lambda x: preprocessing(path_image=x['path_pair_id_2'], path_to_save=x['path_pair_id_2_cropped'], dim=(64,128)), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pair_id_1</th>\n",
       "      <th>pair_id_2</th>\n",
       "      <th>pair_name_1</th>\n",
       "      <th>pair_name_2</th>\n",
       "      <th>path_pair_id_1</th>\n",
       "      <th>path_pair_id_2</th>\n",
       "      <th>path_pair_id_1_cropped</th>\n",
       "      <th>path_pair_id_2_cropped</th>\n",
       "      <th>VJ_pair_id_1</th>\n",
       "      <th>VJ_pair_id_2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>Aaron_Peirsol</td>\n",
       "      <td>None</td>\n",
       "      <td>..\\Data\\lfw2\\Aaron_Peirsol\\Aaron_Peirsol_0001.jpg</td>\n",
       "      <td>..\\Data\\lfw2\\Aaron_Peirsol\\Aaron_Peirsol_0002.jpg</td>\n",
       "      <td>..\\Data\\lfw2_cropped\\Aaron_Peirsol\\Aaron_Peirs...</td>\n",
       "      <td>..\\Data\\lfw2_cropped\\Aaron_Peirsol\\Aaron_Peirs...</td>\n",
       "      <td>(63, 63, 127, 127)</td>\n",
       "      <td>(69, 68, 114, 114)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>Aaron_Peirsol</td>\n",
       "      <td>None</td>\n",
       "      <td>..\\Data\\lfw2\\Aaron_Peirsol\\Aaron_Peirsol_0003.jpg</td>\n",
       "      <td>..\\Data\\lfw2\\Aaron_Peirsol\\Aaron_Peirsol_0004.jpg</td>\n",
       "      <td>..\\Data\\lfw2_cropped\\Aaron_Peirsol\\Aaron_Peirs...</td>\n",
       "      <td>..\\Data\\lfw2_cropped\\Aaron_Peirsol\\Aaron_Peirs...</td>\n",
       "      <td>(61, 61, 130, 130)</td>\n",
       "      <td>(70, 66, 112, 112)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>Aaron_Sorkin</td>\n",
       "      <td>None</td>\n",
       "      <td>..\\Data\\lfw2\\Aaron_Sorkin\\Aaron_Sorkin_0001.jpg</td>\n",
       "      <td>..\\Data\\lfw2\\Aaron_Sorkin\\Aaron_Sorkin_0002.jpg</td>\n",
       "      <td>..\\Data\\lfw2_cropped\\Aaron_Sorkin\\Aaron_Sorkin...</td>\n",
       "      <td>..\\Data\\lfw2_cropped\\Aaron_Sorkin\\Aaron_Sorkin...</td>\n",
       "      <td>(69, 69, 114, 114)</td>\n",
       "      <td>(63, 64, 125, 125)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>Abdel_Nasser_Assidi</td>\n",
       "      <td>None</td>\n",
       "      <td>..\\Data\\lfw2\\Abdel_Nasser_Assidi\\Abdel_Nasser_...</td>\n",
       "      <td>..\\Data\\lfw2\\Abdel_Nasser_Assidi\\Abdel_Nasser_...</td>\n",
       "      <td>..\\Data\\lfw2_cropped\\Abdel_Nasser_Assidi\\Abdel...</td>\n",
       "      <td>..\\Data\\lfw2_cropped\\Abdel_Nasser_Assidi\\Abdel...</td>\n",
       "      <td>(66, 66, 118, 118)</td>\n",
       "      <td>(68, 70, 113, 113)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Abdullah</td>\n",
       "      <td>None</td>\n",
       "      <td>..\\Data\\lfw2\\Abdullah\\Abdullah_0001.jpg</td>\n",
       "      <td>..\\Data\\lfw2\\Abdullah\\Abdullah_0003.jpg</td>\n",
       "      <td>..\\Data\\lfw2_cropped\\Abdullah\\Abdullah_0001.jpg</td>\n",
       "      <td>..\\Data\\lfw2_cropped\\Abdullah\\Abdullah_0003.jpg</td>\n",
       "      <td>(64, 63, 125, 125)</td>\n",
       "      <td>(63, 64, 124, 124)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   pair_id_1  pair_id_2          pair_name_1 pair_name_2  \\\n",
       "0          1          2        Aaron_Peirsol        None   \n",
       "1          3          4        Aaron_Peirsol        None   \n",
       "2          1          2         Aaron_Sorkin        None   \n",
       "3          1          2  Abdel_Nasser_Assidi        None   \n",
       "4          1          3             Abdullah        None   \n",
       "\n",
       "                                      path_pair_id_1  \\\n",
       "0  ..\\Data\\lfw2\\Aaron_Peirsol\\Aaron_Peirsol_0001.jpg   \n",
       "1  ..\\Data\\lfw2\\Aaron_Peirsol\\Aaron_Peirsol_0003.jpg   \n",
       "2    ..\\Data\\lfw2\\Aaron_Sorkin\\Aaron_Sorkin_0001.jpg   \n",
       "3  ..\\Data\\lfw2\\Abdel_Nasser_Assidi\\Abdel_Nasser_...   \n",
       "4            ..\\Data\\lfw2\\Abdullah\\Abdullah_0001.jpg   \n",
       "\n",
       "                                      path_pair_id_2  \\\n",
       "0  ..\\Data\\lfw2\\Aaron_Peirsol\\Aaron_Peirsol_0002.jpg   \n",
       "1  ..\\Data\\lfw2\\Aaron_Peirsol\\Aaron_Peirsol_0004.jpg   \n",
       "2    ..\\Data\\lfw2\\Aaron_Sorkin\\Aaron_Sorkin_0002.jpg   \n",
       "3  ..\\Data\\lfw2\\Abdel_Nasser_Assidi\\Abdel_Nasser_...   \n",
       "4            ..\\Data\\lfw2\\Abdullah\\Abdullah_0003.jpg   \n",
       "\n",
       "                              path_pair_id_1_cropped  \\\n",
       "0  ..\\Data\\lfw2_cropped\\Aaron_Peirsol\\Aaron_Peirs...   \n",
       "1  ..\\Data\\lfw2_cropped\\Aaron_Peirsol\\Aaron_Peirs...   \n",
       "2  ..\\Data\\lfw2_cropped\\Aaron_Sorkin\\Aaron_Sorkin...   \n",
       "3  ..\\Data\\lfw2_cropped\\Abdel_Nasser_Assidi\\Abdel...   \n",
       "4    ..\\Data\\lfw2_cropped\\Abdullah\\Abdullah_0001.jpg   \n",
       "\n",
       "                              path_pair_id_2_cropped        VJ_pair_id_1  \\\n",
       "0  ..\\Data\\lfw2_cropped\\Aaron_Peirsol\\Aaron_Peirs...  (63, 63, 127, 127)   \n",
       "1  ..\\Data\\lfw2_cropped\\Aaron_Peirsol\\Aaron_Peirs...  (61, 61, 130, 130)   \n",
       "2  ..\\Data\\lfw2_cropped\\Aaron_Sorkin\\Aaron_Sorkin...  (69, 69, 114, 114)   \n",
       "3  ..\\Data\\lfw2_cropped\\Abdel_Nasser_Assidi\\Abdel...  (66, 66, 118, 118)   \n",
       "4    ..\\Data\\lfw2_cropped\\Abdullah\\Abdullah_0003.jpg  (64, 63, 125, 125)   \n",
       "\n",
       "         VJ_pair_id_2  \n",
       "0  (69, 68, 114, 114)  \n",
       "1  (70, 66, 112, 112)  \n",
       "2  (63, 64, 125, 125)  \n",
       "3  (68, 70, 113, 113)  \n",
       "4  (63, 64, 124, 124)  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(128, 64)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "test_img = open_img(df_train.loc[0, 'path_pair_id_1_cropped'])\n",
    "print(test_img.shape)\n",
    "plt_img(test_img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: apply HOG in pre processed images (VJ + resize)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### apply HOG: paper 3780 HOG features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_1_HOG = np.array([feature.hog(open_img(img_1), orientations=9, pixels_per_cell=(8, 8), cells_per_block=(2, 2), \n",
    "                                  block_norm='L2', visualize=False, transform_sqrt=False, feature_vector=True, \n",
    "                                  multichannel=False)\n",
    "                      for img_1 in df_train.loc[:,'path_pair_id_1_cropped'].values])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2200, 3780)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_1_HOG.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_2_HOG = np.array([feature.hog(open_img(img_2), orientations=9, pixels_per_cell=(8, 8), cells_per_block=(2, 2), \n",
    "                                  block_norm='L2', visualize=False, transform_sqrt=False, feature_vector=True, \n",
    "                                  multichannel=False)\n",
    "                      for img_2 in df_train.loc[:,'path_pair_id_2_cropped'].values])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2200, 3780)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_2_HOG.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = np.array([[1 if par==None else 0 for par in df_train.loc[:,'pair_name_2'].values]]).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 1100, 1: 1100}"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unique, counts = np.unique(y_train, return_counts=True)\n",
    "dict(zip(unique, counts))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Df_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_1_HOG = np.array([feature.hog(open_img(img_1), orientations=9, pixels_per_cell=(8, 8), cells_per_block=(2, 2), \n",
    "                                  block_norm='L2', visualize=False, transform_sqrt=False, feature_vector=True, \n",
    "                                  multichannel=False)\n",
    "                      for img_1 in df_test.loc[:,'path_pair_id_1_cropped'].values])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_2_HOG= np.array([feature.hog(open_img(img_2), orientations=9, pixels_per_cell=(8, 8), cells_per_block=(2, 2), \n",
    "                                  block_norm='L2', visualize=False, transform_sqrt=False, feature_vector=True, \n",
    "                                  multichannel=False)\n",
    "                      for img_2 in df_test.loc[:,'path_pair_id_2_cropped'].values])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test = np.array([[1 if par==None else 0 for par in df_test.loc[:,'pair_name_2'].values]]).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique, counts = np.unique(y_test, return_counts=True)\n",
    "dict(zip(unique, counts))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Os vetores X_train1_hog e X_train_2 serao concatenados via coluna para o PCA neste experimento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X_train_HOG = np.append(X_train_1_HOG, X_train_2_HOG, axis=1)\n",
    "print(X_train_HOG.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_HOG = np.append(X_test_1_HOG, X_test_2_HOG, axis=1)\n",
    "print(X_test_HOG.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4: PCA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Atenção:\n",
    "- The Step 4 (PCA): is performed on resulting Hog Vector, here will be concatenate hog_vec_1 and hog_vec_2 before PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA().fit(X_train_HOG)\n",
    "plt.plot(np.cumsum(pca.explained_variance_ratio_))\n",
    "plt.xlabel('number of components')\n",
    "plt.ylabel('cumulative explained variance');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for n_components in np.arange(0, X_train_HOG.shape[1], 10):\n",
    "    print(n_components)\n",
    "    if np.sum(pca.explained_variance_ratio_[:n_components])>0.8:\n",
    "        break\n",
    "\n",
    "pca.set_params(**{'n_components':n_components})  \n",
    "X_train_PCA = pca.fit_transform(X=X_train_HOG)\n",
    "print(X_train_PCA.shape)\n",
    "X_test_PCA = pca.transform(X=X_test_HOG)\n",
    "print(X_test_PCA.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.sum(pca.explained_variance_ratio_[:n_components])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.sum(pca.explained_variance_ratio_[:600])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.sum(pca.explained_variance_ratio_[:500])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.sum(pca.explained_variance_ratio_[:400])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca.set_params(**{'n_components':400})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_PCA = pca.fit_transform(X=X_train_HOG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_PCA.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_PCA = pca.transform(X=X_test_HOG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_PCA.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### shuffle data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arr = np.arange(y_train.shape[0])\n",
    "np.random.shuffle(arr)\n",
    "X = X_train_PCA[arr]\n",
    "y_d = y_train[arr]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(X.shape)\n",
    "print(y_d.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Grid SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import accuracy_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SVC()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "param_grid = [\n",
    "  {'C': [1, 5], 'degree': np.arange(1, 5, 2), 'kernel': ['poly']}\n",
    " ]\n",
    "grid = GridSearchCV(SVC(), scoring='accuracy', n_jobs=-1, param_grid=param_grid, verbose=10)\n",
    "grid.fit(X=X, y=y_d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_best = grid.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_best.fit(X, y_d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_test = clf_best.predict(X_test_PCA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_score(y_true=y_test, y_pred=y_pred_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = {'solver': ['sgd'], 'max_iter': [1000, 2000, 5000], \n",
    "              'alpha': 10.0 ** -np.arange(2, 5), 'hidden_layer_sizes':np.arange(10, 100, 5), 'activation':['logistic']}\n",
    "clf = GridSearchCV(MLPClassifier(), parameters, n_jobs=-1, verbose=10, scoring='accuracy')\n",
    "clf.fit(X, y_d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_clf_ = clf.best_estimator_\n",
    "best_clf_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_clf_.fit(X, y_d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_test_ = best_clf_.predict(X_test_PCA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_score(y_true=y_test, y_pred=y_pred_test_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
