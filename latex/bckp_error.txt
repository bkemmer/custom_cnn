\documentclass[conference]{IEEEtran}
\IEEEoverridecommandlockouts
% The preceding line is only needed to identify funding in the first footnote. If that is unneeded, please comment it out.
\usepackage{cite}
\usepackage{amsmath,amssymb,amsfonts}
\usepackage{hyperref}
\usepackage{algorithmic}
\usepackage{graphicx}
\graphicspath{ {./imgs/} }
\usepackage{textcomp}
\usepackage{xcolor}
\def\BibTeX{{\rm B\kern-.05em{\sc i\kern-.025em b}\kern-.08em
    T\kern-.1667em\lower.7ex\hbox{E}\kern-.125emX}}
\begin{document}

\title{Análise comparativa entre técnicas tradicionais de aprendizado de máquina e redes convolucionais para a tarefa de autenticação facial\\
%{\footnotesize \textsuperscript{*}Note: Sub-titles are not captured in Xplore and should not be used}
\thanks{Identify applicable funding agency here. If none, delete this.}
}

\author{\IEEEauthorblockN{Rodolfo Simões}
\IEEEauthorblockA{\textit{Programa de Pós-Graduação em Sistemas de Informação} \\
\textit{Universidade de São Paulo}\\
São Paulo, Brasil \\
rodolfosi.simoes@gmail.com\\
https://orcid.org/0000-0001-6989-1233}
\and
\IEEEauthorblockN{Bruno Kemmer}
\IEEEauthorblockA{\textit{Programa de Pós-Graduação em Sistemas de Informação}\\
\textit{Universidade de São Paulo}\\
São Paulo, Brasil \\
bruno.kemmer@usp.br}
}

\maketitle

\begin{abstract}
This document is a model and instructions for \LaTeX.
This and the IEEEtran.cls file define the components of your paper [title, text, heads, etc.]. *CRITICAL: Do Not Use Symbols, Special Characters, Footnotes, 
or Math in Paper Title or Abstract.
\end{abstract}

\begin{IEEEkeywords}
component, formatting, style, styling, insert
\end{IEEEkeywords}

\section{Introdução}
A tarefa de autenticação facial consiste em validar se duas imagens são da mesma pessoa, ou se são de pessoas distintas. Sua aplicação é muito abrangente, desde biometria até vigilância. O sucesso para o problema está diretamente ligado a representação de características e ao método de classificação empregues \cite{deniz2011face}. Recentemente, atraiu atenção significativa devido à acessibilidade de câmeras digitais e computadores de baixo custo.

O reconhecimento de faces é um problema antigo na visão por computador. Recentemente, atraiu atenção significativa devido à acessibilidade de câmeras digitais e computadores de baixo custo, e suas aplicações em biometria e vigilância. O sucesso para o problema está diretamente ligado a representação de características e ao método de classificação empregues \cite{deniz2011face}.

\section{Definição do problema}

\subsection{Conjuntos de dados}
A base de dados  \textit{"Labeled Faces in the Wild-a"} (LFW-a)\footnote{Disponível em: \url{https://talhassner.github.io/home/projects/lfwa/}.} 
é um conjunto de dados de rostos rotulados oriundo da base de dados LFW\footnote{Disponível em:\url{http://vis-www.cs.umass.edu/lfw/index.html}.}, 
no entanto, aplica-se o alinhamento das faces utilizando um software comercial e sua saída é em escala de tons de cinza. A base de dados pode ser utiliza para problemas de detecção de faces ou autenticação. O segundo cenário, consiste em verificar se duas imagens dadas pertencem ou não a mesma pessoa, aceitando ou rejeitando a entrada, logo é um problema de classificação binária.
A base contém $13.233$ imagens pertencentes a $5.749$ pessoas, sendo $1.680$ com duas ou mais fotos. 
O termo \textit{in the Wild} demonstra que são imagens com ruído, ou seja, podem ter mais de uma face na mesma imagem, podem estar em posições e ângulos distintos.

Além disso, é disponível para propósitos de desenvolvimento a \textit{view} 1, que consiste em uma separação do dataset em dois grupos, treino e teste. Com $1.100$ pares de imagens da mesma pessoa e $1.100$ pares de imagens duas pessoas distintas, totalizando $2.200$ exemplos para a base de treino e $500$ pares (da mesma pessoa e de pessoas distintas), totalizando $1.000$ exemplos para a base de teste. 

\section{Pré-Processamento}\label{sec:preprocess}

Nesta seção, descreve-se a etapa de pré-processamento realizada nas imagens originais da base LFW2. Primeiro, será descrito o método Viola Jones, em seguida, a estratégia de redimensionamento aplicado as imagens. 



\subsection{Viola \& Jones (VJ)}
Um método de detecção de objetos proposto por Paul Viola e Michael Jones \cite{Viola01robustreal-time} \cite{Viola01rapidobject} consiste em identificar atributos similares em faces humanas, utilizando atributos Haar, estes são filtros que aplicados na imagem conseguem identificar padrões, como mudança de intensidade nos pixels em sua orientação vertical, horizontal, diagonal, entre outras.
O método também utiliza um classificador, baseado no método AdaBoost, para selecionar os atributos mais eficientes para detecção das faces presentes na imagem, fazendo isso em forma de cascata, descartando regiões com baixa chance de ter uma face, e continuando o processamento em regiões mais promissoras, o que aumenta sua eficiência computacional.
O método está implementado na biblioteca OpenCV e a função \textit{detectMultiScale} retorna um vetor com as faces detectadas, cada elemento é na forma de 4 valores (coluna (eixo-x), linha (eixo-y), largura e altura). Com isso é possível identificar na imagem original os retângulos das faces identificadas.
Quando mais de uma face foi identificada foi escolhida a de maior área.

\subsection{Redimensionamento (\textit{Resize})}
Como a área da face indenticada pelo método Viola Jones não possui a mesma dimensão para diferentes imagens, a imagem foi redimensionada para que todas ficassem com a mesma dimensão final. A fins, de comparação experimental utilizou-se diferentes valores para o redimensionamento (número de linhas,número de colunas) da imagem pré-processada. Uma visão geral é apresentada na Figura \ref{img:preprocess}.

\begin{figure}[h]\label{img:preprocess}
\centerline{\includegraphics{pre_process.png}}
\caption{Ilustração do pré-processamento realizado nas imagens originais.}
\label{fig}
\end{figure}



\section{Extratores de características}


Após obter a imagem pré-processada (conforme Seção \ref{sec:preprocess}), utilizou-se abordagens para extrair características da imagens resultantes, e em seguida, aplicar os classificadores considerados neste trabalho.



\subsection{Histograms of Oriented Gradients}
Histogram of Oriented Gradient (HOG) foi proposto em \cite{dalal2005histograms} para detecção de pedestres. Os HOG's provaram ser descritores eficazes para o reconhecimento de imagens, comumente utilizados em muitos problemas diferentes na visão computacional, como detecção de objetos, pedestres e o reconhecimento de faces \cite{deniz2011face}. A \textit{feature} HOG é robusta e não é sensível a mudanças geométricas e iluminação, e a complexidade computacional é muito menor que a dos dados originais \cite{li2017face}. Para computar os descritores precisamos realizar os seguintes passos:

\begin{enumerate}
    \item normalização da imagem
    \item computar o gradiente da imagem nos eixos $x$ e $y$ (filtro sobel)
    \item computar o histograma dos gradientes
    \item normalizar os blocos
    \item consolidar num vetor (\textit{flatenning})
\end{enumerate}

O primeiro passo aplica uma normalização na imagem inteira para reduzir a influência dos efeitos de iluminação. O segundo passo calcula os gradientes de primeira ordem da imagem. Isto irá capturar contorno e algumas informações de textura da imagem. O terceiro passo visa produzir uma codificação sensível ao conteúdo local da imagem, mantendo-se resistente a pequenas alterações na pose ou na aparência. O quarto passo calcula a normalização, isso insere uma melhor invariância à iluminação, sombreamento e contraste das bordas. O último passo consolida realiza mapeia a matriz em um vetor.



\begin{figure}[h]
\centerline{\includegraphics[scale=0.55]{imgs/hogprocess2.png}}
\caption{Ilustração do processo de aplicação do HOG
% \footnote{Source: 
% \url{ https://www.learnopencv.com/histogram-of-oriented-gradients/}}
.}
\label{img:hog_process}
\end{figure}

Para os experimentos aqui conduzidos utilizamos um pacote Python para aplicar o HOG\footnote{Disponível em: \url{https://scikit-image.org/docs/dev/auto_examples/features_detection/plot_hog.html}.}. Seguimos a configuração de parâmetros apresentada em \cite{li2017face}, blocos de $(8,8)$ pixels, $bins=9$ para o histograma e normalização com sobreposição em blocos de $(2,2)$. Contudo, dois pontos foram estendidos:
\begin{enumerate}
    \item considerou-se também imagens com \textit{shapes} diferente ao de $(128,64)$;
    \item considerou-se também sobreposição com blocos de $(1,1)$
\end{enumerate}
    
A motivação pela sobreposição com blocos menores é pela redução de dimensionalidade, ou seja, considere uma imagem de tamanho $(128,64)$ com janela de $(8,8)$ pixels e com $bins=9$, a sobreposição em blocos de $(2,2)$ resulta em $3.780$ atributos, já a normalização em blocos de $(1,1)$ resulta em $1.152$ atributos.


\subsection{Independent Component Analysis (ICA)}
    
   A Análise de Componentes Independentes é uma técnica aplicada principalmente na separação cega de fontes (BSS\footnote{Do inglês, Blind Source Separation}). O modelo básico de ICA supõe que as fontes originais são estatisticamente independentes, e com base nesse princípio estima as componentes de forma que estas sejam as mais independentes possíveis. A ICA foi desenvolvida inicialmente para lidar com problemas relacionados com Cocktail Party, cenário onde várias pessoas conversam ao mesmo tempo em uma sala e microfones captam as misturas das vozes \cite{silva2010implementaccao}. Contudo, hoje a técnica é aplicada a diversos problemas de interesse, tal como \textit{face recognition} \cite{toygar2003face} e redução de dimensionalidade \cite{cao2003comparison}.
 
 %A análise de componentes independentes (ICA) é um método estatístico para transformar um vetor aleatório multidimensional observado em seus componentes que são estatisticamente tão independentes um do outro quanto possível [11]. A ICA é um caso especial da técnica de redução de redundância e representa os dados em termos de variáveis estatisticamente independentes.
 %A ICA de um vetor aleatório $x = [x_1, x_2 \cdots, x_M]^T$ consiste na determinação de uma transformação linear $\mathbf{y = Wx}$ de tal maneira que os elementos do vetor aleatório $\mathbf{y} = [y_1, y_2, \cdots, y_N]^T$ otimizem uma função custo $\Psi(\mathbf{y})$, denominada função contraste, que expresse uma medida de independência.
  
Sejam n variáveis aleatórias observadas $x_1, \cdots, x_n$, as misturas captadas pelos sensores em uma abordagem de BBS. Cada $x_i$ é modelado como uma combinação linear de $n$ variáveis aleatórias $s_1, \cdots, s_n$, tal que:
\begin{equation}
    x_i  = a_{in}s_n + a_{i1}s_1 + \cdots + a_{in}s_n,  \quad \forall i, j = 1, \cdots, n
\end{equation}
em que os $a_{ij}$ são os coeficientes de mistura. Por definição, as componentes $s_i$ são estatisticamente independentes. Como uma combinação linear, podemos: $x_i=\sum_{j=1}^{n}a_{ij}s_j$. Adotando um modelo matricial e denotando a matriz formada pelos coeficientes de mistura por $A$, temos que: $x=As$.

O problema da estimativa do modelo ICA apresentado é estimar as componentes independentes, dado que não se tem conhecimento acerca dos coeficientes de mistura e das componentes independentes, ou seja, estimar uma matriz de separação $W$ composta por vetores linha $w_i$, onde $i=1, \cdots, n$, tal que: $s=Wx$. Como a matriz A é desconhecida, não se pode determinar uma matriz W tal que $s$ seja satisfeita, mas podemos encontrar $W^*$ tal que: $y= W^*x$,onde $||s-y|| = min$.
% [RODOLFO] repetido %     
%Comparado com outros métodos estatísticos, o ICA por exemplo, o ICA fornece uma representação de dados mais poderosa que o PCA, porque o PCA considera apenas os momentos de segunda ordem (edificado por meio da correlação/covariância) e não correlaciona os dados, enquanto o ICA é responsável por estatísticas de ordem superior e identifica os dados independentes \cite{toygar2003face}.

Nos experimentos aqui conduzidos, utilizou-se três valores distintos para o número de componentes independentes $[100, 200, 300]$.

\subsection{Local Binary Patterns (LBP)}
Esse extrator de características funciona da seguinte forma:
\begin{enumerate}
    \item A imagem é dividida em seções de pixels (ex.: 16x16)
    \item Todos os pixels ao redor do pixel central são comparados e caso tenham um valor maior (significando uma maior brilho) recebem o valor 1 senão 0.
    \item Esses valores são abertos e computados como um número binário.
    \item É calculado o histograma desses valores.
\end{enumerate}

Na formulação original o histograma teria 256 posições, uma variação comum seria a utilização do padrão uniforme \cite{barkan}, nesta, somente os valores binários com até 2 mudanças de valores seriam armazenados (ex.: 0-1 ou 1-0) em respectivas colunas distintas no histograma e todos os padrões não-uniformes são acumulados na última colunas. Isso reduz consideravelmente a dimensão de saída do histograma e também torna ele invariante a rotação. Na utilização do método também é opcional a normalização dos histogramas. Nos experimentos com LBP e LBPH essa normalização foi utilizada.
Outra variação deste métodos se chamada LBPH, pois nela é aplicada a lógica do LBP mas separando a imagem em seções, passando essa seção para o método LBP e concatenando o histograma resultante. Com isso se mantém uma representação espacial das seções da imagem, já que os histogramas de seções da imagem contíguos são concatenados.
Essa técnica é utilizada para as tarefas de reconhecimento e autenticação facial \cite{heusch_local_2006} \cite{ahonen_face_2006}.

\subsection{Principal Component Analysis (PCA)}
% comentar que foi feito PCA em todas as imagens e essa transformação foi utilizada individualmente

O PCA é uma abordagem popular para obter um conjunto de atributos de baixa dimensão a partir de um grande conjunto de variáveis de um conjunto de variáveis grande \cite{james2013introduction}. Possuí como principais vantagens: retirar a multicolinearidade das variáveis, pois permite transformar um conjunto de variáveis originais intercorrelacionadas em um novo conjunto de variáveis não correlacionadas (componentes principais). Além disso, reduz muitas variáveis a eixos que representam algumas variáveis, sendo estes eixos perpendiculares (ortogonais) explicando a variação dos dados de forma decrescente e independente. 

Seja um conjunto de $p$ variáveis $X_1, \cdots, X_p$  com médias $\mu_1, \cdots, \mu_p$ e variância $\sigma_1, \cdots, \sigma_p$, respectivamente. Basicamente, o 1º Componente Principal (CP) é a combinação linear normalizada dos atributos que contém maior variância. O 2º Componente Principal é a combinação linear dos atributos que contém maior variância de todas as combinações lineares que são descorrelacionadas (ortogonal) com o 1º CP. E assim, por diante \cite{james2013introduction}.

Para os experimentos aqui conduzidos, selecionou-se o número de componentes que representam uma variância acumulada superior a $80\%$ dos dados originais.

%Seja um conjunto de $p$ variáveis $X_1, \cdots, X_p$  com médias $\mu_1, \cdots, \mu_p$ e variância $\sigma_1, \cdots, \sigma_p$, respectivamente. Estas variáveis não são são independentes e portanto, possuem covariância entre a i-ésima e k-ésima variável definida por $\sigma_{ik}$, para $i \neq k = 1, \cdots, p$. 



\subsection{Concatenação}

Como o problema a ser solucionado consiste na análise de duas imagens diferentes para classificarmos se pertencem a mesma pessoa ou não. Realizou-se os passos de pré-processamento e extração de atributos (mencionado anteriormente) e com isso, obtemos vetores de características multidimensionais para cada imagem, e para cada par dos exemplos de treinamento e teste, concatenamos os vetores resultantes para formar os exemplos de treinamento e teste, logo, um exemplo consiste em um vetor em que sua metade inicial são atributos da primeira imagem e sua metade final, da segunda.
%Após todos os passos de pré-processamento terem sido executados, as duas imagens (da mesma pessoa, ou de pessoas distintas) se tornaram vetores unidimensionais, e de mesmo tamanho. 
%Estes foram concatenados, logo, um exemplo consiste em um vetor em que sua metade inicial são atributos da primeira imagem e sua metade final, da segunda.

\section{Classificadores}
\subsection{SVM}

O problema primal para o método Support Vector Machine (SVM) é dado por:

\begin{equation}\label{eq:primal_svm}
\begin{split}
\begin{array}{c}
	\Phi(\mathbf{w}, \xi) = \frac{1}{2}||\mathbf{w}||^2 + C \sum_{i=1}^{N}F(\xi_i) \\
	\textrm{sujeito a: } y_i[(\mathbf{w} \cdot \mathbf{x}_i) + b] \geq 1 - \xi_i, \qquad i = 1, \cdots, N. 
\end{array}
\end{split}
\end{equation}


	O problema dual é apresentado na Equação \ref{eq:dual_svm}.
	
\begin{equation}\label{eq:dual_svm}
\begin{split}
\begin{array}{c}
	\min_{\alpha} W(\alpha) = \frac{1}{2}\sum_{i=1}^{N}\sum_{j=1}^{N} \alpha_i \alpha_j y_i y_j K(\mathbf{x}_i,\mathbf{x}_j) - \sum_{i=1}^{N} \alpha_i\\
\textrm{sujeito a: } 0\leq \alpha_i \leq C, \qquad i = 1, \cdots, N \qquad \sum_{i=1}^N \alpha_i y_i = 0. 
\end{array}
\end{split}
\end{equation}

	Usual em Otimização:
\begin{equation}\label{eq:dual_svm_otimizacao}
\begin{split}
\begin{array}{c}
	\min_{\alpha} W(\alpha) = \frac{1}{2} \alpha P \alpha^T + Q^T \alpha\\
\textrm{sujeito a: } 0\leq \alpha_i \leq C, \qquad i = 1, \cdots, N \qquad A\alpha = 0. 
\end{array}
\end{split}
\end{equation}	
em que, $P = y y^T K$ e $q = -e$ (vetores de 1's).	

	Os valores de $\alpha$ foram encontrados utilizando a biblioteca de otimização em python cvxopt\footnote{Disponível em: \url{http://cvxopt.org/documentation/}.}. Após obter os valores de alpha e selecionar os vetores suporte $(\alpha > 1e-5)$, a predição de uma nova observação $\mathbf{x_j}$ é dada por: 
	
\begin{equation}\label{eq:fx_svm}
\begin{split}
	f(\mathbf{x}) = sign (\sum_{i=1}^{SVs} \alpha_i^* y_i K(\mathbf{x}_i,\mathbf{x}_j) + b^*)\\
	\textrm{em que: } K(\mathbf{x}_i,\mathbf{x}_j) = (<\mathbf{x}_i,\mathbf{x}_j> + 1)^2  \\
	 b = 1/SVs * \sum_{i=1}^{SVs} y_i - \alpha_i y_i K(\mathbf{x}_i,\mathbf{x}_i)
\end{split}
\end{equation}


\subsection{MLP}

A Multilayer Perceptron (MLP) implementada neste trabalho, utiliza a entropia cruzada como função de perda, softmax como função de ativação da camada de saída e função ativação sigmoid na camada oculta, conforme apresentado na Figura \ref{fig:mlp}. 
	
		
\begin{figure}[h]% H manda colocar exatamente nessa posição no texto (relativa aos parágrafos anterior e posterior)
	\centering
 	  \caption{Arquitetura Multilayer Perceptron.}
		\includegraphics[scale=0.4]{imgs/mlp.jpeg}
	\label{fig:mlp}
\end{figure}


A partir da Figura \ref{fig:mlp} é possível entender a estrutura da MLP implementada neste trabalho, em que para $\mathbf{x_i} \in \mathbb{R}^m$, temos que o número de neurônios da camada oculta ($n\_hidden$) é parametrizável e o numéro de saídas ($nc$) é inerente a cada problema. Sendo assim, para o problema temos as seguintes matrizes:
\begin{itemize}
	\item $A$ com o \textit{shape} $(n\_hidden, m)$
	\item $bias\_A$  com o \textit{shape} $(n\_hidden, 1)$
	\item $B$ com o shape $(nc, n\_hidden)$
	\item $bias\_B$ com o shape $(nc, 1)$
\end{itemize}		
	
	
Basicamente, o algoritmo MLP consiste da execução iterativa de dois passos: feed-foward e backpropagation. O primeiro passo é realizado para pegar a saída da rede para cada observação, e consiste dos seguintes passos: 
	\begin{enumerate}
		\item $z_{in} = X * A^T + bias\_A^T$
		\item $z_i = sigmoid(z_{in})$
		\item $y_{in} = z_i * B^T + bias\_B^T$
		\item $y_i = softmax(y_{in})$
		
	\end{enumerate}
	
	
O segundo passo considera o valor da saída da rede para calcular o erro, e em seguida, realiza a atualização das matrizes de pesos. As respectivas derivadas são apresentadas na Equação \ref{eq:derivadas_mlp}.

	
\begin{equation}\label{eq:derivadas_mlp}
\begin{split}
\begin{array}{c}
\nabla B = (y_i - y_d)^T * z_i  \\
\nabla bias\_B = (y_i - y_d) \\
\nabla A = (((y_i - y_d) * B) * \nabla sigmoid(z_{in}))^T * x_i \\
\nabla bias\_A = (((y_i - y_d) * B) * \nabla sigmoid(z_{in}))^T
\end{array}
\end{split}
\end{equation}


\subsection{Ensemble: MLP com correlação negativa}

Para este trabalho, considerou-se a abordagem de ensemble apresentada em \cite{liu1999ensemble}. 

Os autores descrevem o problema da seguinte forma: suponha que temos um conjunto de dados $D = \{(\mathbf{x_1}, d_1), \cdots, (\mathbf{x_N}, d_N)\}$, em que $\mathbf{x} \in \mathbb{R}^p$, $d$ é um escalar e $N$ é o tamanho do conjunto de treinamento. Estima-se $d$ ao formar um ensemble cuja saída é uma simples média das saídas do conjunto de redes neurais, conforme \ref{eq:ens_neg_cor_predict}.
	
\begin{equation}\label{eq:ens_neg_cor_predict}
F(n) = \frac{1}{M} \sum_{i=1}^{M} F_i (n),
\end{equation}
em que $M$ é o número de redes neurais no ensemble, $F_i(n)$ é a saída da rede $i$ para a $nth$ instância de treinamento.

Negative correlation learning insere um termo de penalidade (correlação) na função e erro de cada rede no ensemble, tal que todas as redes pode ser treinadas simultaneamente no mesmo conjunto de treinamento $D$. A função de erro $E_i$ para a rede $i$ é definida como:
	
\begin{equation}\label{eq:ens_neg_cor_error}
E_i = \frac{1}{N} \sum_{n=1}^{N} E_i (n) = \frac{1}{N} \sum_{n=1}^{N} \frac{1}{2} (F_i(n) - d(n))^2 + \frac{1}{N} \sum_{n=1}^{N} \lambda p_i (n),
\end{equation}
em que $E_i(n)$ é o valor da função de erro da rede $i$ para a $nth$ instância de treinamento. O primeiro termo do lado direito da Eq \ref{eq:ens_neg_cor_error} é o risco empírico da rede $i$. O segundo termo $p_i$ é a função de penalidade de correlação. O objetivo de minimizar $p_i$ é correlacionar negativamente cada erro da rede com os erros do resto do ensemble.

	O parâmetro $0 \leq \lambda \leq 1$ é utilizado para ajustar a penalidade. A função de penalidade $p_i$ é definada a seguir:
	
\begin{equation}
p_i(n) = (F_i(n) - F(n)) \sum_{j \neq i} (F_j(n) - F(n))
\end{equation}

A derivada parcial do erro $E_i (n)$ para a saída da rede $i$ considerando a $nth$ observação de treinamento é dada por:

\begin{equation}\label{eq:ens_neg_cor_der_error}
\frac{\partial E_i(n)}{\partial F_i(n)} = (1 - \lambda) (F_i(n)-d(n)) + \lambda (F(n) - d(n)).
\end{equation}

Note que para $\lambda = 1$ a Eq \ref{eq:ens_neg_cor_der_error} resume-se para $F(n)-d(n)$. Os autores utilizaram o algoritmo backpropagation para atualizar os pesos das rede com a metodologia padrão a padrão. Além disso, consideraram quatro redes no ensemble. Cada rede neural com uma camada oculta, com dez neurônios na camada oculta. Como função de ativação utilizaram a sigmoid, tanto para a camada oculta quanto para a camada de sáida. A camada de saída foi representa pelo encoding one-of-n, a saída com maior ativação corresponde a classe atribuída.

A implementação realizada para este trabalho seguiu a arquitetura do ensemble mencionada no parágrafo anterior. A fim de ilustração, a Figura \ref{fig:ens_mlp} apresenta a arquitetura da rede.
	
	
\begin{figure}[h]% H manda colocar exatamente nessa posição no texto (relativa aos parágrafos anterior e posterior)
	\centering
 	  \caption{Arquitetura de uma rede neural $i$ do ensemble.}
		\includegraphics[scale=0.4]{imgs/mlp_2.jpeg}
	\label{fig:ens_mlp}
\end{figure}
	
	
	As atualizações das matrizes $A$ e $B$ do classificador $i$ foram realizadas conforme as Equações \ref{Eq:ens_neg_cor_upd_A}, \ref{Eq:ens_neg_cor_upd_B}, respectivamente. Além disso, utilizou-se como valor para a taxa de aprendizagem $\alpha=0.1$ e como critério de parada 500 épocas.
	
\begin{equation}\label{Eq:ens_neg_cor_upd_B}
\begin{split}
\begin{array}{c}
\frac{\partial E(n)}{\partial b_{ki}} = \frac{\partial E(n)}{\partial e_{k}} \frac{\partial e_{k}}{\partial Y_k} \frac{\partial Y_k}{\partial Y_{in}} \frac{\partial Y_{in}}{\partial b_k}\\
= \frac{\partial E_i(n)}{\partial F_i(n)} \frac{\partial F_i(n)}{\partial Y_{in}} \frac{\partial Y_{in}}{\partial b_k} \\
= (((1 - \lambda) (F_i(n)-d(n)) + \lambda (F(n) - d(n)))  g^{'}(Y_{in}))^T Z_i
\end{array}
\end{split}
\end{equation}


\begin{equation}\label{Eq:ens_neg_cor_upd_A}
\begin{split}
\begin{array}{c}
\frac{\partial E(n)}{\partial a_{ij}} = \frac{\partial E(n)}{\partial Z_{i}} \frac{\partial Z_i}{\partial a_{ij}},\\
\frac{\partial e_k}{\partial Z_i} = \frac{\partial e_k(n)}{\partial y_k(n)} \frac{\partial y_k(n)}{\partial Y_{in}} \frac{\partial Y_{in}}{\partial Z_{in}} \\
= \frac{\partial E_i(n)}{\partial F_i(n)} \frac{\partial F_i(n)}{\partial Y_{in}} \frac{\partial Y_{in}}{\partial Z_{in}} \\
=(((1 - \lambda) (F_i(n)-d(n)) + \lambda (F(n) - d(n)))  g^{'}(Y_{in})) b_{ki},\\
\frac{\partial Z_i}{\partial a_{ij}} = \frac{\partial Z_i}{\partial Z_{in}} \frac{\partial Z_{in}}{\partial a_{ij}}\\
= f^{'}(Z_{in}) X
\end{array}
\end{split}
\end{equation}







\subsection{CNN}
Redes neurais convolucionais\cite{lecun_89} são redes neurais que executam uma ou mais vezes a operação matemática de convolução, um exemplo é apresentado na Figura \ref{fig:cnn}. Essa operação consiste em aplicar na matriz de entrada ($x(a)$)  uma função de \textit{kernel} ($w(t-a)$), dada por: 
\begin{equation}\label{Eq:conv}
    s(t) = \int x(a)w(t-a)da = (x*w)(t).
\end{equation}
Em sua saída é aplicada uma função de ativação não linear. 

\begin{figure}[h]% H manda colocar exatamente nessa posição no texto (relativa aos parágrafos anterior e posterior)
	\centering
 	  \caption{Exemplo de uma convolução 2D, com um kernel 2x2.\cite{Goodfellow-et-al-2016}}
		\includegraphics[scale=0.45]{imgs/cnn.png}
	\label{fig:cnn}
\end{figure}

Na arquitetura da rede também existem camadas de sub-amostragem essas executam uma agregação dos dados da camada anterior (em geral a função máximo (\textit{max pooling}) ou média (\textit{average pooling}), reduzindo sua dimensionalidade, e ruido. Ao final a saída é aberta (\textit{flatten}) em uma ou mais camadas totalmente conectadas que determinam a classe da instância. Na Figura \ref{fig:alexnet} apresenta-se uma arquitetura de CNN, a rede AlexNet.



Redes neurais convolucionais trazem benefícios:
\begin{itemize}
    \item Podem identificar padrões de forma hierárquica. Ex.: detecção de formas geométricas, atributos como olhos, bocas, narizes e nas camadas posteriores, a classe final, conforme Figura \ref{fig:cat}.
    \item Também são invariantes a translação, podendo detectar padrões não importando onde eles apareçam.
\end{itemize}

\begin{figure*}[h]% H manda colocar exatamente nessa posição no texto (relativa aos parágrafos anterior e posterior)
	\centering
 	  \caption{Ilustração da arquitetura da rede AlexNet \cite{krizhevsky_imagenet_2017}}
		\includegraphics[scale=0.55]{imgs/alex_net.png}
	\label{fig:alexnet}
\end{figure*}

\begin{figure}[h]% H manda colocar exatamente nessa posição no texto (relativa aos parágrafos anterior e posterior)
	\centering
 	  \caption{Ilustração da classificação de forma hierárquica.\cite{chollet_deep_2018}}
		\includegraphics[scale=0.45]{imgs/cat.png}
	\label{fig:cat}
\end{figure}





\section{Experimentos}

Apresenta-se primeiro nesta seção, os detalhes dos experimentos conduzidos, em seguida os resultados obtidos.

\subsection{Configuração experimental}

    Como mencionado anteriormente, para cada imagem (original) dos conjuntos de treinamento e teste, aplicamos o método Viola Jones e em seguida, realizamos o redimensionamento das imagens para padronizar o número de atributos extraídos no passo adiante.  Primeiramente, definiu-se valores nos quais pode-se manter a proporção de números de linhas e colunas em $1:1$ (retorno do algoritmo Viola Jones) e $2:1$ (indicado em \cite{li2017face}), os valores escolhidos foram $[(28,28), (64,32), (64,64), (128,64), (100,100)]$.
    
    Em seguida, para cada conjunto de imagens (\textit{shape} diferente) aplicamos os métodos de extração de características HOG, LBP, LBPH, ICA e PCA. Nos experimentos conduzidos aplicamos o PCA apenas combinando com a saída do extrator HOG, objetivo de redução de dimensionalidade. Por fim, aplicamos os métodos de classificação SVM, MLP, Ensemble e CNN, tal processo é indicado na Figura \ref{fig:processo}. Ressalta-se que para a CNN não foi considerado a etapa de \textit{featurizer}, com isso, utilizou-se as imagens resultantes do pré-processamento para treinar a CNN. 
    
    
    \begin{figure}[h]% H manda colocar exatamente nessa posição no texto (relativa aos parágrafos anterior e posterior)
	\centering
 	  \caption{Ilustração das etapas realizadas para a aplicação dos classificadores nos experimentos conduzidos.}
		\includegraphics[scale=0.52]{imgs/processo2.png}
	\label{fig:processo}
\end{figure}
    
    
\subsubsection{Validação Cruzada}
Para obter os melhores hiper-parâmetros foi utilizado o método \textit{k-fold} com k=5, foi tomado o cuidado de estratificar a divisão respeitando a proporção de classes do dataset original, ou seja foi utilizada a validação cruzada estratificada. Em que o dataset de \textbf{treino} foi dividido em cinco partes, quatro utilizadas para treinar os modelos e uma para testa-los. Isso foi feito para cada elemento de todas as combinações de hiper-parâmetros utilizadas para treino.

Foram analisados os resultados obtidos e com esses hiper-parâmetros otimizados, o modelo foi treinado novamente obtendo a acurácia no dataset de teste.

Também é importante notar que inicialmente foram testados múltiplas combinações dos hiper-parâmetros de pré-processamento, com isso encontramos os valores que tinham os melhores resultados, e esses foram utilizados para otimizar os hiper-parâmetros dos classificadores.
\subsubsection{Hyper-parâmetros testados}
Foi feita uma busca exaustivas nas seguintes combinações de hiper-parâmetros dos classificadores:
SVM:
\begin{enumerate}
    \item C: \{1, 10, 100\}
    \item Kernels (para SVM e TWSVM): \{'Linear', 'Polinomial'\}
    \item Graus (para o kernel polinomial): \{1, 2, 3\}
\end{enumerate}

MLP:
\begin{enumerate}
    \item Taxas de aprendizado: \{0,1, 0,5, 1\}
    \item Máximo de iterações/Épocas: \{500, 1.000, 5.000\}
    \item Funções Ativação: \{'\textit{Sigmoid}', '\textit{Relu}'\}
    \item Quantidade de neurônios na camada escondida: \{ 10, 100, 500\}
\end{enumerate}

Para o Ensemble: MLP com correlação negativa, foram utilizados os hiper-parâmetros da MLP e testados com 2 e 3 classificadores.



Para a CNN, por questões computacionais utilizou-se inicialmente a biblioteca Python Keras\footnote{Disponível em: \url{https://keras.io/} para testar diferentes configurações de arquitetura para a rede. Os melhores resultados apresentaram uma 




\subsection{Resultados}

\begin{table}[htbp]
\caption{Table Type Styles}
\begin{center}
\begin{tabular}{|c|c|c|c|}
\hline
\textbf{Table}&\multicolumn{3}{|c|}{\textbf{Table Column Head}} \\
\cline{2-4} 
\textbf{Head} & \textbf{\textit{Table column subhead}}& \textbf{\textit{Subhead}}& \textbf{\textit{Subhead}} \\
\hline
copy& More table copy$^{\mathrm{a}}$& &  \\
\hline
\multicolumn{4}{l}{$^{\mathrm{a}}$Sample of a Table footnote.}
\end{tabular}
\label{tab1}
\end{center}
\end{table}


\section{Considerações finais}




\bibliographystyle{IEEEtran}
\bibliography{bibliografia}






\end{document}
